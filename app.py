
# --- Gerekli KÃ¼tÃ¼phaneler ---
import streamlit as st
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import pandas as pd
import numpy as np
import os
from streamlit.errors import StreamlitAPIException, StreamlitSecretNotFoundError
from sklearn.metrics.pairwise import cosine_similarity

# --- Sayfa AyarlarÄ± ---
st.set_page_config(
    page_title="RAG Bilgi AsistanÄ±",
    page_icon="ğŸ§ ", # Daha teknolojik bir ikon
    layout="wide"
)

# --- CSS ile KÃ¼Ã§Ã¼k DokunuÅŸlar (Ä°steÄŸe BaÄŸlÄ±) ---
st.markdown("""
<style>
    /* Butonun gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ biraz deÄŸiÅŸtir */
    .stButton>button {
        border-radius: 20px;
        border: 2px solid #FF4B4B;
        color: #FF4B4B;
        background-color: transparent;
    }
    .stButton>button:hover {
        border-color: #FF6B6B;
        color: #FF6B6B;
    }
    /* Kenar Ã§ubuÄŸunu biraz daha belirgin yap */
    [data-testid="stSidebar"] {
        background-color: #f0f2f6; /* AÃ§Ä±k tema iÃ§in */
    }
    /* Koyu tema iÃ§in (isteÄŸe baÄŸlÄ±) */
    /*
    [data-testid="stSidebar"] {
        background-color: #1E1E1E; 
    }
    */
</style>
""", unsafe_allow_html=True)

# --- 1. Ä°lk Kurulum ve Modelleri YÃ¼kleme ---
@st.cache_resource
def load_models_and_data():
    print("Loading models and data...")
    local_model = SentenceTransformer('all-mpnet-base-v2')
    try:
        df_final = pd.read_pickle("my_rag_library_local.pkl")
    except FileNotFoundError:
        st.error("KÃ¼tÃ¼phane dosyasÄ± (my_rag_library_local.pkl) bulunamadÄ±.")
        return None, None, None
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    except (KeyError, StreamlitSecretNotFoundError, StreamlitAPIException):
        try:
            api_key = os.environ.get('GOOGLE_API_KEY')
            if not api_key: raise ValueError("GOOGLE_API_KEY not found")
            genai.configure(api_key=api_key)
        except Exception as e:
            st.error(f"API Key yapÄ±landÄ±rÄ±lamadÄ±. Hata: {e}")
            return None, None, None
    generative_model = genai.GenerativeModel('models/gemini-2.5-flash')
    print("Models and data loaded.")
    return local_model, generative_model, df_final

# --- 2. RAG FonksiyonlarÄ± ---
# (find_best_passages_local ve generate_answer fonksiyonlarÄ± Ã¶ncekiyle aynÄ±,
#  buraya tekrar eklemiyorum ama dosyada olmalÄ±lar)
def find_best_passages_local(query, dataframe, local_model, top_k=3):
    query_embedding = local_model.encode(query)
    doc_embeddings = np.stack(dataframe['Embeddings'].to_numpy())
    similarities = cosine_similarity(query_embedding.reshape(1, -1), doc_embeddings)[0]
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    # Sadece description dÃ¶ndÃ¼relim, prompt iÃ§in bu yeterli
    return "\n---\n".join(dataframe.iloc[top_indices]['description'].tolist())

def generate_answer(query, dataframe, local_model, generative_model):
    context = find_best_passages_local(query, dataframe, local_model)
    prompt = f"""
    You are a helpful bot. Answer the user's QUESTION based ONLY on the CONTEXT provided.
    If the answer is not in a context, say "I couldn't find an answer in the provided documents."
    CONTEXT: {context}
    QUESTION: {query}
    ANSWER:
    """
    try:
        response = generative_model.generate_content(prompt)
        # CevabÄ± biraz temizleyelim (Markdown'dan kaÃ§Ä±ÅŸ karakterlerini vb.)
        clean_response = response.text.strip()
        return clean_response
    except Exception as e:
        return f"Cevap Ã¼retme sÄ±rasÄ±nda bir hata oluÅŸtu: {e}"


# --- 3. Streamlit ArayÃ¼z Kodu (GeliÅŸtirilmiÅŸ) ---

# Ana baÅŸlÄ±k (Markdown ile daha bÃ¼yÃ¼k ve ortalanmÄ±ÅŸ)
st.markdown("<h1 style='text-align: center; color: #FF4B4B;'>ğŸ§  RAG Bilgi AsistanÄ±</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>SQuAD veri setini kullanan RAG tabanlÄ± bir chatbot demosu</p>", unsafe_allow_html=True)
st.divider()

# Modelleri ve veriyi yÃ¼kle
local_model, generative_model, df_final = load_models_and_data()

# Kenar Ã‡ubuÄŸu (Sidebar) Elementleri
with st.sidebar:
    st.image("https://streamlit.io/images/brand/streamlit-logo-secondary-colormark-darktext.svg", width=200) # Streamlit logosu (isteÄŸe baÄŸlÄ±)
    st.header("â“ Soru Sor")
    st.markdown("SQuAD veri setindeki (Wikipedia makaleleri) bilgilere dayanarak sorularÄ±nÄ±zÄ± yanÄ±tlamaya Ã§alÄ±ÅŸÄ±rÄ±m.")
    user_query = st.text_area("Sorunuz:", placeholder="Which NFL team won Super Bowl 50?", height=100) # text_input yerine text_area daha geniÅŸ alan saÄŸlar
    submit_button = st.button("ğŸš€ Cevap Al")

# Ana Alan (Cevap Ä°Ã§in)
if local_model and generative_model and (df_final is not None):
    if submit_button:
        if user_query:
            # Cevap alanÄ± iÃ§in bir yer tutucu oluÅŸtur
            answer_placeholder = st.empty()
            answer_placeholder.info("â³ CevabÄ±nÄ±z aranÄ±yor ve oluÅŸturuluyor...")
            
            # RAG sistemini Ã§alÄ±ÅŸtÄ±r
            answer = generate_answer(user_query, df_final, local_model, generative_model)
            
            # Yer tutucuyu temizle ve cevabÄ± gÃ¶ster
            answer_placeholder.empty()
            st.subheader("ğŸ¤– AsistanÄ±n CevabÄ±:")
            # CevabÄ± daha belirgin bir kutuda gÃ¶ster
            st.markdown(f"> {answer}") 
        else:
            st.warning("âš ï¸ LÃ¼tfen bir soru girin.")
else:
    st.error("âŒ Modeller veya veri yÃ¼klenemediÄŸi iÃ§in uygulama baÅŸlatÄ±lamadÄ±.")
